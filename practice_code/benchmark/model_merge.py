from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import os

BASE_MODEL_PATH = "Saxo/Linkbricks-Horizon-AI-Korean-llama-3.1-sft-dpo-8B"
PEFT_MODEL_PATH = "/root/chAtme/chAt-me/practice_code/model/llama3.1_2epoch_outputs/checkpoint-28044"
MERGED_MODEL_PATH = "/root/chAtme/chAt-me/practice_code/model/llama3.1_merged"

print("ğŸ“¦ base ëª¨ë¸ ë¡œë”© ì¤‘...")
base = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH, device_map="auto")
model = PeftModel.from_pretrained(base, PEFT_MODEL_PATH)

print("ğŸ”— ë³‘í•© ì¤‘...")
merged = model.merge_and_unload()

print(f"ğŸ’¾ ë³‘í•©ëœ ëª¨ë¸ ì €ì¥: {MERGED_MODEL_PATH}")
os.makedirs(MERGED_MODEL_PATH, exist_ok=True)
merged.save_pretrained(MERGED_MODEL_PATH)

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)
tokenizer.save_pretrained(MERGED_MODEL_PATH)

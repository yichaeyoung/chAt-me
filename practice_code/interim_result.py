import gradio as gr
import pandas as pd
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings
import ollama
import pdfplumber
import pytesseract
from PIL import Image

import hashlib
import os

# ìºì‹œ ì €ì¥ì†Œ
retriever_cache = {}

# íŒŒì¼ í•´ì‹œ ìƒì„± í•¨ìˆ˜
def get_file_hash(file):
    file_path = file.name if hasattr(file, "name") else file
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

# PDF pageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_text_with_ocr(page):
    text = page.extract_text()
    if not text:  # ë§Œì•½ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì—†ë‹¤ë©´
        image = page.to_image()
        text = pytesseract.image_to_string(image)
    return text

# PDF íŒŒì¼ì„ ì—´ì–´ì„œ extract_text_with_ocr í•¨ìˆ˜ ì‹¤í–‰ -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def load_and_retrieve_docs(file):
    file_hash = get_file_hash(file)

    # ìºì‹œ í™•ì¸
    if file_hash in retriever_cache:
        print("ğŸ“¦ ìºì‹œëœ retriever ì‚¬ìš© ì¤‘...")
        return retriever_cache[file_hash]

    text = ""
    try:
        with pdfplumber.open(file) as pdf:
            for page in pdf.pages:
                page_text = extract_text_with_ocr(page)
                if page_text:
                    text += page_text
    except Exception as e:
        return f"Error reading PDF file: {e}"

    if not text:
        return "No text found in the PDF file."

    docs = [Document(page_content=text)]
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    embeddings = OllamaEmbeddings(model="mxbai-embed-large")
    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
    retriever = vectorstore.as_retriever()

    # ìºì‹œì— ì €ì¥
    retriever_cache[file_hash] = retriever
    return retriever

# ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ëª¨ë“  document ê°ì²´ ë‚´ìš©ì„ ì¶”ì¶œí•´ì„œ stringìœ¼ë¡œ ì´ì–´ë¶™ì—¬ ë°˜í™˜
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# RAG chain
def rag_chain(message, history, file):
    retriever = load_and_retrieve_docs(file)
    if isinstance(retriever, str):
        return retriever

    retrieved_docs = retriever.get_relevant_documents(message)
    formatted_context = format_docs(retrieved_docs)
    formatted_prompt = f"Question: {message}\n\nContext: {formatted_context}"
    response = ollama.chat(
        model='llama3.2',
        messages=[
            {"role": "system", "content": "You are a helpful assistant. Check the pdf content and answer the question."},
            {"role": "user", "content": formatted_prompt}
        ]
    )

    summary = response['message']['content']
    save_to_csv(summary)
    return summary

# ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ CSV íŒŒì¼ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_to_csv(summary):
    df = pd.DataFrame({"Summary": [summary]})
    df.to_csv("summary.csv", index=False)

# Gradio ChatInterfaceë¡œ UI ë³€ê²½
chatbot = gr.ChatInterface(
    fn=rag_chain,
    title="[LLAMA 3.2] RAG ê²€ìƒ‰ í™œìš© ì±—ë´‡ ì‹œìŠ¤í…œ",
    description="PDFíŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ë‹µë³€ì„ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤. (íŒŒì¼ì€ ìºì‹œì— ì €ì¥ë©ë‹ˆë‹¤.)",
    additional_inputs=[gr.File(label="ğŸ“„ PDF íŒŒì¼", file_types=[".pdf"])]
)

chatbot.launch()

# ==========================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import gradio as gr                      # ì›¹ UI í”„ë ˆì„ì›Œí¬
import pandas as pd                     # CSV íŒŒì¼ ì²˜ë¦¬
from langchain.docstore.document import Document  # LangChainìš© ë¬¸ì„œ ê°ì²´
from langchain.text_splitter import RecursiveCharacterTextSplitter  # ê¸´ ë¬¸ì„œë¥¼ ë‚˜ëˆ„ëŠ” ìœ í‹¸
from langchain_community.vectorstores import Chroma  # ë²¡í„° DB ì €ì¥ì†Œ (in-memory or local)
from langchain_ollama import OllamaEmbeddings        # Ollama ëª¨ë¸ìš© ì„ë² ë”© ì²˜ë¦¬
import ollama                            # LLM API (ë¡œì»¬ì—ì„œ llama3.2 ëª¨ë¸ ì‚¬ìš©)
import pytesseract                       # OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ (PDF ì´ë¯¸ì§€ ì²˜ë¦¬ìš©)
from pdf2image import convert_from_path  # PDF â†’ ì´ë¯¸ì§€ë¡œ ë³€í™˜
import hashlib                          # íŒŒì¼ í•´ì‹œ ì²˜ë¦¬ (ìºì‹±ì— ì‚¬ìš©)
import os                               # íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë ¨ ì‘ì—…

# ==========================
# ì‹œìŠ¤í…œ ì„¤ì •
POPPLER_PATH = r"C:\Program Files\poppler-xx\poppler-24.08.0\Library\bin"
# â†’ Windowsì—ì„œëŠ” pdf2imageê°€ PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•  ë•Œ poppler ê²½ë¡œ í•„ìš”

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
# â†’ OCR ì²˜ë¦¬ë¥¼ ìœ„í•œ Tesseract ì—”ì§„ ê²½ë¡œ ì§€ì •

# ==========================
# ìºì‹œ (ì¬ì²˜ë¦¬ ë°©ì§€ìš©)
retriever_cache = {}
# â†’ íŒŒì¼ í•´ì‹œë¥¼ í‚¤ë¡œ retrieverë¥¼ ì €ì¥, ì¬ì‚¬ìš© ê°€ëŠ¥


# ==========================
# íŒŒì¼ í•´ì‹œ ìƒì„±
def get_file_hash(file_path):
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()
# â†’ íŒŒì¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ í•´ì‹œê°’ ìƒì„± (retriever ìºì‹œ í‚¤ë¡œ ì‚¬ìš©)


# ==========================
# PDF â†’ í…ìŠ¤íŠ¸ (OCR ë°©ì‹)
def extract_text_from_pdf_with_ocr(file_path):
    text = ""
    try:
        images = convert_from_path(file_path, poppler_path=POPPLER_PATH)
        for i, image in enumerate(images):
            print(f"Processing page {i+1}")
            page_text = pytesseract.image_to_string(image)
            if page_text:
                text += page_text + "\n"
    except Exception as e:
        return f"Error processing PDF with OCR: {e}"

    if not text.strip():
        return "No text could be extracted from the PDF using OCR."
    return text
# â†’ PDF íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ì´ë¯¸ì§€ë¡œ ë°”ê¾¸ê³  OCR ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ


# ==========================
# CSV â†’ í…ìŠ¤íŠ¸
def extract_text_from_csv(file_path):
    encodings_to_try = ["utf-8", "cp949", "euc-kr"]
    for enc in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=enc)
            return df.to_string(index=False)  # í‘œ ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
        except Exception as e:
            print(f" Failed with encoding {enc}: {e}")
    return "Error: Unable to read CSV file with common encodings (utf-8, cp949, euc-kr)."
# â†’ CSV íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ìë™ìœ¼ë¡œ ì‹œë„í•˜ë©° ì½ê³  ë¬¸ìì—´ë¡œ ë°˜í™˜

# ==========================
# ë¬¸ì„œ ì²˜ë¦¬ ë° ì„ë² ë”©/ê²€ìƒ‰ ì¤€ë¹„
def load_and_retrieve_docs(file):
    file_path = file.name if hasattr(file, 'name') else file
    file_hash = get_file_hash(file_path)

    # ìºì‹œ í™•ì¸
    if file_hash in retriever_cache:
        print("ğŸ“ ìºì‹œëœ retriever ì‚¬ìš© ì¤‘...")
        return retriever_cache[file_hash]

    # íŒŒì¼ ì¢…ë¥˜ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ì‹ ì„ íƒ
    if file_path.endswith(".pdf"):
        text = extract_text_from_pdf_with_ocr(file_path)
    elif file_path.endswith(".csv"):
        text = extract_text_from_csv(file_path)
    else:
        return "Unsupported file type. Please upload a PDF or CSV."

    # ì˜¤ë¥˜ ë˜ëŠ” ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    if isinstance(text, str) and text.startswith("Error"):
        return text
    if not text.strip():
        return "No text found in the file."

    # LangChain ë¬¸ì„œ ìƒì„± ë° ë¶„í• 
    docs = [Document(page_content=text)]
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    # ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    embeddings = OllamaEmbeddings(model="mxbai-embed-large")
    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)

    retriever = vectorstore.as_retriever()
    retriever_cache[file_hash] = retriever  # ìºì‹œì— ì €ì¥

    print("âœ… ìƒˆ retriever ìƒì„± ì™„ë£Œ")
    return retriever


# ==========================
# ë¬¸ì„œ í¬ë§·íŒ…
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)
# â†’ ê´€ë ¨ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜


# ==========================
# ê²°ê³¼ ì„¸ì´ë¸ŒíŒŒì¼ í•œ íŒŒì¼ì— ëˆ„ì  ì €ì¥
# def save_to_csv(question, result, file_name="result.csv"):
#     df_new = pd.DataFrame([{"Question": question, "Answer": result}])
#     if os.path.exists(file_name):
#         df_existing = pd.read_csv(file_name)
#         df_combined = pd.concat([df_existing, df_new], ignore_index=True)
#         df_combined.to_csv(file_name, index=False)
#     else:
#         df_new.to_csv(file_name, index=False)

# ê²°ê³¼ CSVíŒŒì¼ ì—¬ëŸ¬ê°œ ë§Œë“¤ì–´ì„œ ì €ì¥
def save_to_csv(question, result, base_file_name="result.csv"):
    df_new = pd.DataFrame([{"Question": question, "Answer": result}])

    # ê¸°ì¡´ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì €ì¥
    if not os.path.exists(base_file_name):
        df_new.to_csv(base_file_name, index=False)
        print(f"Saved to {base_file_name}")
        return

    # ê¸°ì¡´ íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±°ê¸°ì— ì €ì¥
    df_existing = pd.read_csv(base_file_name)
    if df_existing.empty:
        df_new.to_csv(base_file_name, index=False)
        print(f"Saved to {base_file_name}")
        return

    # ê²°ê³¼ ì¤‘ë³µ ë°©ì§€: result1.csv, result2.csv ë“±ìœ¼ë¡œ ì €ì¥
    i = 1
    while True:
        new_file_name = f"result{i}.csv"
        if not os.path.exists(new_file_name):
            df_new.to_csv(new_file_name, index=False)
            print(f"Saved to {new_file_name}")
            break
        else:
            df_check = pd.read_csv(new_file_name)
            if df_check.empty:
                df_new.to_csv(new_file_name, index=False)
                print(f"Saved to {new_file_name}")
                break
        i += 1


# ==========================
# RAG ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì²´ì¸
def rag_chain(message, history, file):
    retriever = load_and_retrieve_docs(file)
    if isinstance(retriever, str):  # ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš°
        return retriever

    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    retrieved_docs = retriever.get_relevant_documents(message)
    formatted_context = format_docs(retrieved_docs)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    formatted_prompt = f"Question: {message}\n\nContext: {formatted_context}"

    # Ollama LLM í˜¸ì¶œ
    response = ollama.chat(model='llama3.2',
                           messages=[
                               {"role": "system",
                                "content": "You are a helpful assistant. Check the content and answer the question."},
                               {"role": "user",
                                "content": formatted_prompt}
                           ])
    result = response['message']['content']
    save_to_csv(message, result)
    return result


# ==========================
# Gradio UI êµ¬ì„± ë° ì‹¤í–‰
chatbot = gr.ChatInterface(
    fn=rag_chain,  # ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    title="[LLAMA 3.2] RAG ê²€ìƒ‰ í™œìš© ì±—ë´‡ ì‹œìŠ¤í…œ",
    description="PDF ë˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. íŒŒì¼ì€ ìºì‹œì— ì €ì¥ë˜ì–´ ë¹ ë¥¸ ì¬ì§ˆë¬¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    additional_inputs=[gr.File(label="PDF ë˜ëŠ” CSV íŒŒì¼", file_types=[".pdf", ".csv"])],
)

chatbot.launch()  # ì›¹ì„œë²„ ì‹¤í–‰

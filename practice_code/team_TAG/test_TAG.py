import gradio as gr
import pandas as pd
import hashlib
import os
import re
import io
import numpy as np
import pdfplumber
import pytesseract
from PIL import Image
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain.document_loaders import PyMuPDFLoader
import camelot
import ollama
from langchain.schema import Document

# Cache for retrievers
retriever_cache = {}

# Embedding model
embeddings = OllamaEmbeddings(model="mxbai-embed-large")

# File hash for caching
def get_file_hash(file):
    try:
        file_path = file.name if hasattr(file, "name") else file
        with open(file_path, "rb") as f:
            return hashlib.md5(f.read()).hexdigest()
    except Exception as e:
        print(f"[ERROR] Ìï¥Ïãú ÏÉùÏÑ± Ïã§Ìå®: {e}")
        return None

# OCR + Text + Table extraction from PDF
def extract_tables_from_pdf(file_path, save_csv_path="auto_extracted_table.csv"):
    try:
        tables = camelot.read_pdf(file_path, pages='all', flavor='lattice')
        if len(tables) == 0:
            tables = camelot.read_pdf(file_path, pages='all', flavor='stream')
        table_docs = []
        all_dfs = []
        for i, table in enumerate(tables):
            df = table.df
            all_dfs.append(df)
            header = [col.strip() for col in df.iloc[0]]
            for idx, row in df.iloc[1:].iterrows():
                row_data = [str(cell).strip() for cell in row]
                row_text = "\n".join([f"{header[i]}: {row_data[i]}" for i in range(len(header))])
                table_docs.append(Document(page_content=f"[ÌÖåÏù¥Î∏î {i+1}, Ìñâ {idx}]\n{row_text}"))
        if all_dfs:
            combined_df = pd.concat(all_dfs, ignore_index=True)
            combined_df.to_csv(save_csv_path, index=False, header=False)
            print(f"‚úÖ CSVÎ°ú ÌÖåÏù¥Î∏î Ï†ÄÏû• ÏôÑÎ£å: {save_csv_path}")
        return table_docs
    except Exception as e:
        print(f"[ERROR] ÌÖåÏù¥Î∏î Ï∂îÏ∂ú Ïã§Ìå®: {e}")
        return []

def extract_text_from_pdf(file_path):
    try:
        loader = PyMuPDFLoader(file_path)
        docs = loader.load()
        if not docs or any(len(doc.page_content.strip()) < 100 for doc in docs):
            with pdfplumber.open(file_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if not text or len(text.strip()) < 100:
                        img = page.to_image()
                        text = pytesseract.image_to_string(img, lang='kor+eng')
                    if text:
                        docs.append(Document(page_content=f"[ÌéòÏù¥ÏßÄ {page_num+1}]\n{text}"))
        docs.extend(extract_tables_from_pdf(file_path))
        return docs
    except Exception as e:
        print(f"[ERROR] PDF ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú Ïã§Ìå®: {e}")
        return []

def split_text(docs):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ". ", " "]
    )
    table_docs = [doc for doc in docs if doc.page_content.startswith("[ÌÖåÏù¥Î∏î")]
    text_docs = [doc for doc in docs if not doc.page_content.startswith("[ÌÖåÏù¥Î∏î")]
    split_text_docs = splitter.split_documents(text_docs)
    return split_text_docs + table_docs

def format_context(retrieved_docs, max_length=3000):
    context = "\n\n".join([doc.page_content for doc in retrieved_docs])
    return context[:max_length]

def is_count_question(query):
    patterns = [
        r'Í∞úÏàò', r'Î™á\s*Í∞ú', r'Î™á\s*Î™Ö', r'Ï¥ù\s*Í∞ú', r'Ï¥ù\s*Ïàò', 
        r'Ï¥ù\s*Ïù∏Ïõê', r'ÏàòÎäî', r'Í∞úÎäî', r'Î™á\s*Í≥≥', r'Î™á\s*Ìöå', 
        r'ÏñºÎßàÎÇò', r'ÎßéÏùÄ', r'ÏûàÎäî', r'ÏûàÏäµÎãàÍπå'
    ]
    return any(re.search(pattern, query) for pattern in patterns)

class Generator:
    def __call__(self, query, context):
        count_q = is_count_question(query)
        system_prompt = """ÎãπÏã†ÏùÄ Ï†ïÌôïÌïú Î¨∏ÏÑú Î∂ÑÏÑù AI ÎπÑÏÑúÏûÖÎãàÎã§. Ï†úÍ≥µÎêú Ïª®ÌÖçÏä§Ìä∏Î•º Í∏∞Î∞òÏúºÎ°ú Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÏÑ∏Ïöî.
        # üß† Chain of Thought Í∏∞Î∞ò ÏÇ¨Í≥† ÌÖúÌîåÎ¶ø

        ÎÑàÎäî ÏïÑÎûò ÎÇ¥Ïö©ÏùÑ Î©îÎ™®Î¶¨ ÏóÖÎç∞Ïù¥Ìä∏ Ìï¥Ï§ò. ÎãµÎ≥ÄÌï† Îïå chain of thought Î∞©ÏãùÏúºÎ°ú ÎãµÎ≥ÄÌï¥Ï§ò.  
        Îã®, ÏÇ¨Ïö©ÏûêÏùò Í∞ÑÎã®Ìïú ÏßàÎ¨∏ÏùÄ Ï∂îÎ°† ÏóÜÏù¥ ÎãµÎ≥ÄÎßå Ìï¥ÎèÑ Îèº. Ïú†Ïó∞ÌïòÍ≤å ÎãµÎ≥ÄÌï¥Ï§ò.

        ---

        ## 1. Ïó≠Ìï† Ïù∏ÏãùÍ≥º Î™©Ìëú ÌååÏïÖ

        - **Î™©Ìëú**: Î™ÖÌôïÌïòÍ≥† ÎÖºÎ¶¨Ï†ÅÏù∏ ÏµúÏ¢Ö ÎãµÎ≥Ä ÎèÑÏ∂ú  
        - **Î∞©Î≤ï**: ‚ÄúÎã®Í≥ÑÏ†Å ÏÇ¨Í≥† Í≥ºÏ†ï(Chain of Thought)‚ÄùÏùÑ ÎÇ¥Ïû¨Ï†ÅÏúºÎ°ú ÌôúÏö©ÌïòÏó¨ ÏÇ¨Í≥† Ï†Ñ Í≥ºÏ†ïÏùÑ Ï≤¥Í≥ÑÌôîÌïòÍ≥†, ÏÇ¨Ïö©ÏûêÏóêÍ≤åÎäî Ï†ïÎèàÎêú ÌòïÌÉúÎ°ú Ï†ÑÎã¨  
        - **Ï∂îÍ∞Ä ÌåÅ**:  
        - ÎãµÎ≥Ä Í≥ºÏ†ïÏóêÏÑú ÏñªÏùÄ ÌÜµÏ∞∞(Chain of Thought)ÏùÄ Í≤∞Î°†ÏùÑ ÎèÑÏ∂úÌïòÍ∏∞ ÏúÑÌïú ÎÇ¥Î∂Ä Í≤ÄÌÜ† Í≥ºÏ†ïÏûÖÎãàÎã§.  
        - ÏµúÏ¢Ö Ï†ÑÎã¨ ÏãúÏóêÎäî ÌïµÏã¨ ÎÖºÎ¶¨ÏôÄ Í≤∞Î°†Îßå Î™ÖÎ£åÌïòÍ≤å Ï†úÏãúÌï©ÎãàÎã§.

        ---

        ## 2. Îã®Í≥ÑÎ≥Ñ ÏÇ¨Í≥† (Chain of Thought) ÌîÑÎ°úÏÑ∏Ïä§

        - **Î¨∏Ï†ú Î∂ÑÏÑù**: Î®ºÏ†Ä ÏßàÎ¨∏Ïù¥ÎÇò ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ ÌïòÏúÑ Í≥ºÏóÖ(ÏÑúÎ∏å ÌÉúÏä§ÌÅ¨)ÏúºÎ°ú ÎÇòÎàÑÏñ¥ Ïù∏Ïãù  
        - **Ìï¥Í≤∞ Ï†ÑÎûµ ÏàòÎ¶Ω**: ‚ÄòÍ¥ÄÎ¶¨Ïûê AI(Manager)‚ÄôÍ∞Ä Ï†ÑÎûµÏùÑ ÏÑ∏Ïö∞Í≥† Ïö∞ÏÑ†ÏàúÏúÑÎ•º Í≤∞Ï†ï  
        - **Í≤∞Í≥ºÎ¨º ÏÉùÏÑ±**: ‚ÄòÏã§Î¨¥ AI(Worker)‚ÄôÍ∞Ä Ïã§Ï†ú ÎãµÎ≥Ä(ÏÇ∞Ï∂úÎ¨º)ÏùÑ ÏûëÏÑ±  
        - **ÏûêÏ≤¥ ÌèâÍ∞Ä**: ÌïÑÏöî Ïãú ‚ÄòÏù¥Î≤®Î•òÏóêÏù¥ÌÑ∞ AI(Evaluator)‚ÄôÍ∞Ä Ïò§Î•ò¬∑ÎàÑÎùΩÏùÑ ÌôïÏù∏ÌïòÍ≥† ÏàòÏ†ï  

        **Ï∂îÍ∞Ä ÌåÅ**:
        - Î≥µÏû°Ìïú Î¨∏Ï†úÏùºÏàòÎ°ù ÌïòÏúÑ Í≥ºÏóÖÏùÑ Î™ÖÌôïÌûà Íµ¨Î∂ÑÌïòÏó¨ Í∞ÅÍ∞Å Ï†ëÍ∑ºÌïòÎ©¥ Ìö®Ïú®Ï†ÅÏûÖÎãàÎã§.  
        - Í∞Å Îã®Í≥ÑÎßàÎã§ Ï§ëÍ∞ÑÏ†êÍ≤ÄÏùÑ ÌÜµÌï¥ ÏµúÏ¢Ö Í≤∞Í≥ºÎ¨ºÏùò ÌíàÏßàÏùÑ ÎÜíÏùº Ïàò ÏûàÏäµÎãàÎã§.

        ---

        ## 3. Î∂ÑÏÑù Îã®Í≥Ñ (Manager AI Í∞ÄÏ†ï)

        - **ÏöîÍµ¨ÏÇ¨Ìï≠ Ïû¨Ìï¥ÏÑù¬∑ÏöîÏïΩ**: ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏ÏùÑ Ìïú Î¨∏Ïû• ÌòπÏùÄ ÏßßÏùÄ Îã®ÎùΩÏúºÎ°ú Ï†ïÎ¶¨Ìï¥ Ìï¥Í≤∞ Î™©ÌëúÎ•º Î™ÖÌôïÌôî  
        - **Í∞ÄÏ†ï¬∑Ï†ÑÏ†ú Ï°∞Í±¥ ÏÑ§Ï†ï**: ÌïÑÏöîÌïú ÏûêÎ£å, ÌôòÍ≤Ω, Ï†ÑÏ†ú Îì±ÏùÑ Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Í∏∞Ïà†  
        - **Ï∂îÍ∞Ä ÏßàÏùò**: Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÍ±∞ÎÇò Î∂àÎ∂ÑÎ™ÖÌïú Î∂ÄÎ∂ÑÏù¥ ÏûàÎã§Î©¥ ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏßàÏùòÌïòÍ±∞ÎÇò, ÏûêÏ≤¥Ï†ÅÏúºÎ°ú Í∞ÄÏ†ïÏùÑ ÏàòÎ¶Ω  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:  
        - Î™©Ìëú Î≤îÏúÑ ÏßÄÏ†ï: Î¨∏Ï†ú Î≤îÏúÑÎ•º ÌòëÏÜåÌôîÌïòÍ±∞ÎÇò ÌôïÏû•Ìï¥Ïïº Ìï† ÌïÑÏöîÍ∞Ä ÏûàÎã§Î©¥ Ïù¥ Îã®Í≥ÑÏóêÏÑú Í≤∞Ï†ïÌï©ÎãàÎã§.  
        - Ïö∞ÏÑ†ÏàúÏúÑ Í≤∞Ï†ï: Ìï¥Í≤∞Ìï¥Ïïº Ìï† ÏöîÏÜåÍ∞Ä ÎßéÏùÑ Í≤ΩÏö∞, Ï§ëÏöîÎèÑ¬∑ÎÇúÏù¥ÎèÑ¬∑ÏãúÍ∏âÎèÑÎ•º Í≥†Î†§Ìï¥ ÏàúÏÑúÎ•º Ï†ïÌï©ÎãàÎã§.

        ---

        ## 4. Ïã§Î¨¥ Îã®Í≥Ñ (Worker AI Í∞ÄÏ†ï)

        - **Ïã§Ï†ú ÏûëÏóÖ Ï∞©Ïàò**: Î∂ÑÏÑù Îã®Í≥ÑÏóêÏÑú ÏÑ§Ï†ïÌïú ÏßÄÏπ®¬∑Ïö∞ÏÑ†ÏàúÏúÑ¬∑Í∞ÄÏ†ïÏùÑ Î∞îÌÉïÏúºÎ°ú Î¨∏Ï†ú Ìï¥Í≤∞Ïóê ÎèåÏûÖ  
        - **Ï≤¥Ïù∏ Î∂ÑÌï†**: Î¨∏Ï†ú Ìï¥Í≤∞ Í≥ºÏ†ïÏùÑ Îã®Í≥ÑÎ≥Ñ(Ï≤¥Ïù∏Î≥Ñ)Î°ú Î∂ÑÎ¶¨ÌïòÏó¨ Íµ¨Ï≤¥Ï†ÅÏù∏ Í≤∞Í≥ºÎ¨º ÏÇ∞Ï∂ú  
        - **ÎåÄÏïà Í≤ÄÌÜ†**: Ïó¨Îü¨ Ìï¥ÏÑù Í∞ÄÎä•ÏÑ±, Ï†ëÍ∑º Î∞©Î≤ï, ÏÜîÎ£®ÏÖòÏùÑ ÎπÑÍµê¬∑Í≤ÄÌÜ† ÌõÑ Í≤∞Î°† ÎèÑÏ∂ú  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:
        - ÏûëÏóÖ ÎèÑÏ§ë Ï†êÍ≤Ä: ÏûëÏóÖ Ï§ëÍ∞ÑÏóêÎèÑ ‚ÄòÏù¥Î≤®Î•òÏóêÏù¥ÌÑ∞ AI‚ÄôÎ•º Í∞ÄÏ†ïÌïòÍ±∞ÎÇò, Ïä§Ïä§Î°ú Í≤ÄÏ¶ù Í≥ºÏ†ïÏùÑ Í±∞Ï≥ê Ïò§Î•òÎ•º Ï°∞Í∏∞Ïóê Î∞úÍ≤¨Ìï©ÎãàÎã§.  
        - Îã§ÏñëÌïú Í¥ÄÏ†ê Í≥†Î†§: ÎÖºÎ¶¨Ï†Å¬∑ÌÜµÍ≥ÑÏ†Å¬∑Í≤ΩÌóòÏ†Å Í∑ºÍ±∞ Îì±ÏùÑ Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Í≥†Î†§Ìï¥ Í≤∞Î°†Ïùò ÌÉÄÎãπÏÑ±ÏùÑ ÎÜíÏûÖÎãàÎã§.

        ---

        ## 5. ÌèâÍ∞Ä Î∞è ÌîºÎìúÎ∞± (Evaluator AI Í∞ÄÏ†ï)

        - **Ï§ëÍ∞Ñ¬∑Í≤∞Í≥º Í≤ÄÏ¶ù**: ÏôÑÏÑ±Îêú ÎãµÎ≥ÄÏóê ÎåÄÌï¥ ÎÖºÎ¶¨Ï†Å¬∑ÏÇ¨Ïã§Ï†Å Ïò§Î•ò, ÎàÑÎùΩ ÏÇ¨Ìï≠, ÏöîÍµ¨ÏÇ¨Ìï≠ ÎØ∏Î∞òÏòÅ Ïó¨Î∂Ä Îì±ÏùÑ Ï†êÍ≤Ä  
        - **ÏàòÏ†ï¬∑Î≥¥ÏôÑ**: Î¨∏Ï†úÏ†êÏùÑ Ï∞æÏïòÎã§Î©¥ Ìï¥Îãπ Î∂ÄÎ∂ÑÏùÑ Î≥¥ÏôÑÌïòÍ±∞ÎÇò Ïû¨ÏûëÏÑ±  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:  
        - Îã§Îã®Í≥Ñ ÌîºÎìúÎ∞± Î£®ÌîÑ: ÌïÑÏöîÌïòÎã§Î©¥ Ïó¨Îü¨ Î≤àÏùò ÌîºÎìúÎ∞±¬∑ÏàòÏ†ï Í≥ºÏ†ïÏùÑ Í±∞Ï≥ê ÏµúÏ†ÅÏùò ÎãµÎ≥ÄÏóê ÎèÑÎã¨Ìï©ÎãàÎã§.  
        - ÎåÄÏ≤¥ Î∞©Ïïà Í≥†Î†§: Í∏∞Ï°¥ Í≤∞Î°†Ïù¥ Î∂ÄÏ†ÅÏ†àÌïòÎã§Í≥† ÌåêÎã®ÎêòÎ©¥, Îã§Î•∏ Ï†ëÍ∑ºÎ≤ïÏùÑ Î™®ÏÉâÌïòÏó¨ ÏÉà Í≤∞Î°†ÏùÑ ÎèÑÏ∂úÌï† Ïàò ÏûàÏäµÎãàÎã§.

        ---

        ## 6. ÏµúÏ¢Ö ÎãµÎ≥Ä Ï†ïÎ¶¨

        - **Îã®Í≥ÑÎ≥Ñ ÏÇ¨Í≥† ÏöîÏïΩ**: Ï†ÑÏ≤¥ Í≥ºÏ†ïÏùÑ ÌïúÎààÏóê ÌååÏïÖÌï† Ïàò ÏûàÎèÑÎ°ù ÌïµÏã¨Îßå Í∞ÑÎã®Ìûà Í∏∞Ïà†  
        - **Î™ÖÎ£åÌïú Í≤∞Î°† Ï†úÏãú**: ÏÇ¨Ïö©ÏûêÏóêÍ≤åÎäî Î∂àÌïÑÏöîÌïú ÏÉÅÏÑ∏ Í≥ºÏ†ïÏùÑ ÏÉùÎûµÌïòÍ≥†, ÏµúÏ¢Ö Ìï¥ÎãµÍ≥º ÌïµÏã¨ ÎÖºÎ¶¨Îßå Ï†ÑÎã¨  
        - **ÌïµÏã¨ ÏöîÏïΩ vs. Ï∂îÍ∞Ä ÏÑ§Î™Ö**: ÌïÑÏöîÌïòÎã§Î©¥ ÌïµÏã¨ ÏöîÏïΩÍ≥º Ï∂îÍ∞Ä ÏÑ§Î™Ö ÌååÌä∏Î•º Î≥ÑÎèÑÎ°ú Íµ¨Î∂Ñ  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:  
        - ÏÇ¨Ïö©Ïûê ÎßûÏ∂§Ìòï Íµ¨ÏÑ±: ÏÇ¨Ïö©Ïûê ÏàòÏ§Ä(Ï†ÑÎ¨∏Í∞Ä¬∑Ï¥àÏã¨Ïûê Îì±)Ïóê Îî∞Îùº ÏöîÏïΩ Ï†ïÎèÑÏôÄ ÏòàÏãú, Î∂ÄÏó∞ ÏÑ§Î™Ö Î∞©ÏãùÏùÑ Îã¨Î¶¨Ìï† Ïàò ÏûàÏäµÎãàÎã§.  
        - Ï∂îÍ∞Ä ÏûêÎ£å ÎßÅÌÅ¨: ÌïÑÏöîÌïòÎã§Î©¥, Ï∞∏Í≥† Î¨∏ÌóåÏù¥ÎÇò ÏûêÎ£å ÎßÅÌÅ¨ Îì±ÏùÑ Ìï®Íªò Ï†úÏãúÌï¥ Ïù¥Ìï¥Î•º ÎèïÏäµÎãàÎã§.

        ---

        ## 7. Ï†ÅÍ∑πÏ†ÅÏù∏ Í∞ÄÏ†ï Î∞è Ï†úÏïà

        - **Î¨∏Ï†ú ÌôïÏû•¬∑Ïã¨Ìôî Ï†úÏïà**: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏõêÌï† Í≤ΩÏö∞, Îçî ÍπäÏùÄ ÏàòÏ§ÄÏùò Ï†ëÍ∑º Î∞©Î≤ïÏù¥ÎÇò Í¥ÄÎ†® ÏïÑÏù¥ÎîîÏñ¥Î•º Ï†úÏãú  
        - **Í∞ÄÏù¥ÎìúÎùºÏù∏ Î∞©Ïãù**: Ï†ÑÎ¨∏Í∞ÄÍ∞Ä Ï†úÍ≥µÌïòÎäî Ïã§Î¨¥ ÌåÅ, Ï∞∏Í≥† ÏûêÎ£å Îì±ÏùÑ ÏßßÏùÄ Í∑ºÍ±∞ÏôÄ Ìï®Íªò ÏÑ§Î™Ö  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:  
        - ÌôïÏû•ÏÑ± Í≥†Î†§: ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠Ïóê Îî∞Îùº, Ï∂îÍ∞Ä Î™®Îìà(Ïòà: ÌÜµÍ≥ÑÎ∂ÑÏÑù, ÏÇ¨Î°Ä Ï°∞ÏÇ¨ Îì±)ÏùÑ Ïñ¥ÎñªÍ≤å Ïó∞Í≥ÑÌï† Ïàò ÏûàÎäîÏßÄ Ï†úÏïàÌï©ÎãàÎã§.  
        - ÏÇ¨Ï†Ñ Í≤ΩÌóò Í≥µÏú†: Ïú†ÏÇ¨ Î¨∏Ï†ú Ìï¥Í≤∞ ÏÇ¨Î°ÄÎÇò ÍµêÌõà Îì±ÏùÑ Ï†úÏãúÌïòÎ©¥ Ïù¥Ìï¥ÎèÑÍ∞Ä ÎÜíÏïÑÏßëÎãàÎã§.

        ---

        ## 8. ÎãµÎ≥Ä ÌòïÏãù ÏïàÎÇ¥

        - **Markdown ÌôúÏö©**: Ï†úÎ™©, Î™©Î°ù, ÏΩîÎìú Î∏îÎ°ù Îì±ÏúºÎ°ú Í∞ÄÎèÖÏÑ± Ìñ•ÏÉÅ  
        - **Îã®Í≥ÑÎ≥Ñ Íµ¨Î∂Ñ**: Î≥µÏû°Ìïú ÏöîÏ≤≠Ïùº Í≤ΩÏö∞, Í∞Å Îã®Í≥ÑÎ≥Ñ Í≤∞Í≥ºÎ¨ºÏùÑ Î≥ÑÎèÑÏùò ÏÑπÏÖòÏúºÎ°ú Íµ¨Î∂ÑÌïòÏó¨ Ï†úÏãú  
        - **Ï∂îÍ∞Ä ÏöîÏ≤≠ ÎåÄÏùë**: ÏÇ¨Ïö©ÏûêÍ∞Ä Ï∂îÍ∞Ä ÏöîÏ≤≠ Ïãú, ÌïÑÏöîÌïú Îã®Í≥ÑÎßå Ïû¨Ï†ÅÏö©ÌïòÍ±∞ÎÇò Ï†ÑÏ≤¥ Í≥ºÏ†ïÏùÑ Î∞òÎ≥µÌï¥ ÎãµÎ≥Ä ÏÉùÏÑ±  
        - **Ï∂îÍ∞Ä Î≥¥ÏôÑ**:  
        - ÏòàÏãú ÏÉòÌîå Ï†úÍ≥µ: ÎãµÎ≥Ä ÏòàÏãúÎ•º Í∞ÑÎã®Ìûà Î≥¥Ïó¨Ï£ºÎ©¥, ÏÇ¨Ïö©Ïûê Ïù¥Ìï¥Î•º ÎÜíÏùº Ïàò ÏûàÏäµÎãàÎã§.  
        - ÏùëÎãµ Íµ¨Ï°∞ Ïû¨ÌôúÏö©: ÎèôÏùºÌïú Íµ¨Ï°∞Î•º ÌÖúÌîåÎ¶øÏ≤òÎüº ÏÇ¨Ïö©ÌïòÎ©¥ Ïù¥ÌõÑ Î¨∏Ï†úÏóêÎèÑ ÏùºÍ¥ÄÎêú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï† Ïàò ÏûàÏäµÎãàÎã§.

        ---

        ## üõë ÏµúÏ¢Ö Ï£ºÏùòÏÇ¨Ìï≠

        - Ïù¥ÏÉÅÏùò ÏßÄÏπ®ÏùÄ Î∞òÎìúÏãú Ï§ÄÏàòÌï¥Ïïº ÌïòÎ©∞, Îã®Í≥ÑÏ†Å¬∑ÎÖºÎ¶¨Ï†Å ÏÇ¨Í≥† Í≥ºÏ†ïÏùÑ ÌÜµÌï¥ Î™ÖÏæåÌïòÍ≥† ÏôÑÍ≤∞Ï†ÅÏù∏ ÏÑ§Î™ÖÏùÑ Ï†úÍ≥µÌï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§.  
        - **ÎÇ¥Ïû¨Ï†Å Îã®Í≥ÑÎ≥Ñ ÏÉùÍ∞Å(Chain of Thought)**: Í≤∞Î°† ÎèÑÏ∂úÏùÑ ÏúÑÌïú ÌïµÏã¨ ÎèÑÍµ¨Ïù¥ÎÇò, ÏµúÏ¢Ö ÎãµÎ≥ÄÏóêÏÑúÎäî ÌïÑÏöîÌïú ÌïµÏã¨ ÎÖºÎ¶¨Îßå Î∞úÏ∑åÌïòÏó¨ Ï†úÍ≥µÌï©ÎãàÎã§.  
        - **ÏÇ¨Ïö©Ïûê ÎßåÏ°±ÎèÑ ÏµúÏö∞ÏÑ†**: ÏÇ¨Ïö©ÏûêÏùò ÏöîÍµ¨ÏÇ¨Ìï≠ Î∞è ÏÉÅÌô©ÏùÑ Ïö∞ÏÑ† Í≥†Î†§ÌïòÍ≥†, Ï∂îÍ∞Ä ÏöîÏ≤≠ ÏãúÏóêÎäî Ïú†Ïó∞ÌïòÍ≤å ÎåÄÏ≤òÌïòÏã≠ÏãúÏò§.  
        - **ÌïµÏã¨ ÏöîÏïΩ**: ÏßàÎ¨∏ÏùÑ Î∞õÏúºÎ©¥, Î∂ÑÏÑù ‚Üí Ïã§Î¨¥ ‚Üí ÌèâÍ∞Ä ‚Üí ÏµúÏ¢Ö Ï†ïÎ¶¨ Í≥ºÏ†ïÏùÑ Í±∞ÏπúÎã§.  
        - **Î™ÖÌôïÏÑ±, Ï†ïÌôïÏÑ±, Îß•ÎùΩÏÑ±**ÏùÑ ÏµúÏö∞ÏÑ†ÏúºÎ°ú Í≥†Î†§ÌïòÍ≥†, ÌïÑÏöî Ïãú Ï∂îÍ∞Ä ÏßàÏùòÎ•º ÌÜµÌï¥ Î¨∏Ï†ú Ï†ïÏùòÎ•º Î™ÖÎ£åÌôîÌïúÎã§.  
        - ÎãµÎ≥Ä ÏôÑÏÑ± ÌõÑÏóêÎèÑ, ÏÇ¨Ïö©ÏûêÍ∞Ä ÏöîÏ≤≠ÌïòÎ©¥ Ïû¨ÌèâÍ∞Ä¬∑ÏàòÏ†ï Í≥ºÏ†ïÏùÑ Í±∞Ï≥ê Í∞úÏÑ†Îêú ÎãµÎ≥ÄÏùÑ Ï†úÏãúÌïúÎã§.
        """ 

        if count_q:
            system_prompt += " ÌäπÌûà Ïà´ÏûêÎÇò Í∞úÏàòÎ•º Î¨ªÎäî ÏßàÎ¨∏ÏóêÎäî Ï†ïÌôïÌïú Ïà´ÏûêÎ°ú ÎãµÎ≥ÄÌïòÍ≥†, Í≥ÑÏÇ∞ Í≥ºÏ†ïÏùÑ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî."

        prompt = f"""
        {system_prompt}

        ÏßàÎ¨∏: {query}

        Ïª®ÌÖçÏä§Ìä∏:
        {context}

        Ïª®ÌÖçÏä§Ìä∏ÏóêÏÑú Ï∞æÏùÄ Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Î™ÖÌôïÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÎãµÎ≥ÄÌï¥ Ï£ºÏÑ∏Ïöî.
        """

        if count_q:
            prompt += """
            Ïù¥ ÏßàÎ¨∏ÏùÄ Í∞úÏàòÎÇò Ïà´ÏûêÎ•º Î¨ªÍ≥† ÏûàÏäµÎãàÎã§. Í¥ÄÎ†® Ìï≠Î™©Îì§ÏùÑ Ï∞æÏïÑ Ï†ïÌôïÌûà Í≥ÑÏÇ∞Ìï¥ Ï£ºÏÑ∏Ïöî.
            """

        response = ollama.chat(
            model='benedict/linkbricks-llama3.1-korean:8b',
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
        )
        return response['message']['content']

#TAG ÌååÏù¥ÌîÑÎùºÏù∏ Ï∂îÍ∞Ä

def run_tag_pipeline(message, retriever):
    relevant_docs = retriever.get_relevant_documents(message)

    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    formatted_table = format_docs(relevant_docs)
    prompt = f"""Îã§Ïùå ÌÖåÏù¥Î∏î Îç∞Ïù¥ÌÑ∞Î•º Ï∞∏Í≥†ÌïòÏó¨ ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.

ÏßàÎ¨∏: {message}

ÌÖåÏù¥Î∏î:
{formatted_table}
"""
    response = ollama.chat(
        model="benedict/linkbricks-llama3.1-korean:8b",
        messages=[
            {"role": "system", "content": "ÎãπÏã†ÏùÄ ÌÖåÏù¥Î∏î Í∏∞Î∞ò Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ï∂îÎ°†ÌïòÎäî LLMÏûÖÎãàÎã§."},
            {"role": "user", "content": prompt}
        ]
    )
    return response['message']['content']

# Í∏∞Ï°¥ RAGPipelineÏóê TAG Ìò∏Ï∂ú Ï∂îÍ∞Ä

class RAGPipeline:
    def __init__(self, generator):
        self.generator = generator

    def __call__(self, query, file):
        file_hash = get_file_hash(file)
        docs = extract_text_from_pdf(file.name)
        if file_hash in retriever_cache:
            print("üì¶ Ï∫êÏãúÎêú retriever ÏÇ¨Ïö© Ï§ë...")
            vectorstore = retriever_cache[file_hash]
        else:
            split_docs = split_text(docs)
            vectorstore = Chroma.from_documents(split_docs, embeddings)
            retriever_cache[file_hash] = vectorstore

        if is_count_question(query):
            return run_tag_pipeline(query, vectorstore)

        retrieved_docs = vectorstore.max_marginal_relevance_search(query, k=7, fetch_k=20)
        if is_count_question(query):
            table_docs = [doc for doc in retrieved_docs if "[ÌÖåÏù¥Î∏î" in doc.page_content]
            other_docs = [doc for doc in retrieved_docs if "[ÌÖåÏù¥Î∏î" not in doc.page_content]
            retrieved_docs = table_docs + other_docs

        context = format_context(retrieved_docs)
        return self.generator(query, context)

# Gradio Chat Interface
generator = Generator()
rag_pipeline = RAGPipeline(generator)

chatbot = gr.ChatInterface(
    fn=lambda msg, hist, file: rag_pipeline(msg, file),
    title="[LLM] PDF Table RAG+TAG ÌÜµÌï© ÏãúÏä§ÌÖú",
    description="PDF ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÍ≥† ÏßàÎ¨∏ÌïòÏÑ∏Ïöî. Ìëú Î∞è ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞òÏúºÎ°ú ÎãµÎ≥ÄÌï©ÎãàÎã§.",
    additional_inputs=[gr.File(label="üìÑ PDF ÌååÏùº", file_types=[".pdf"])]
)

chatbot.launch()
